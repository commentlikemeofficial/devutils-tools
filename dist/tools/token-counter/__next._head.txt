1:"$Sreact.fragment"
2:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/d2be314c3ece3fbe.js"],"ViewportBoundary"]
3:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/d2be314c3ece3fbe.js"],"MetadataBoundary"]
4:"$Sreact.suspense"
5:I[27201,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/d2be314c3ece3fbe.js"],"IconMark"]
0:{"buildId":"3KkKdpaJR1obetBl8fcqp","rsc":["$","$1","h",{"children":[null,["$","$L2",null,{"children":[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]}],["$","div",null,{"hidden":true,"children":["$","$L3",null,{"children":["$","$4",null,{"name":"Next.Metadata","children":[["$","title","0",{"children":"Token Counter | DevUtils"}],["$","meta","1",{"name":"description","content":"Estimate token counts for GPT-4, Claude, and other LLMs using tiktoken-style encoding. Optimize your prompts and stay within limits."}],["$","meta","2",{"name":"author","content":"DevUtils"}],["$","meta","3",{"name":"keywords","content":"token counter,GPT-4,Claude,OpenAI,tiktoken,AI,LLM"}],["$","meta","4",{"property":"og:title","content":"Token Counter | DevUtils"}],["$","meta","5",{"property":"og:description","content":"Estimate token counts for GPT-4, Claude, and other LLMs"}],["$","meta","6",{"property":"og:type","content":"website"}],["$","meta","7",{"name":"twitter:card","content":"summary"}],["$","meta","8",{"name":"twitter:title","content":"Token Counter | DevUtils"}],["$","meta","9",{"name":"twitter:description","content":"Estimate token counts for GPT-4, Claude, and other LLMs"}],["$","link","10",{"rel":"icon","href":"/favicon.ico?favicon.0b3bf435.ico","sizes":"256x256","type":"image/x-icon"}],["$","$L5","11",{}]]}]}]}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],"loading":null,"isPartial":false}
